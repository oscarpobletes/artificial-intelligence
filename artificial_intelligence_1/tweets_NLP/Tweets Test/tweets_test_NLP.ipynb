{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hxjcOgg9BK4-"},"source":["# Natural Language Processing for sentiment classification (Deep Learning)\n","\n","Óscar Poblete Sáenz <br> Course: Introduction to Artificial Intelligence<br>\n","Teacher: Elizabeth Guevara Martinez<br>\n","Universidad Anáhuac <br> <br>\n","Sources:<br>\n","\n","Zhang, Ye & Wallace, Byron.  A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification. arXiv.  2015<br>\n","Vishnu K https://digitaltesseract.com/sentiment-analyzer-using-convolutional-neural-network/"]},{"cell_type":"code","metadata":{"id":"gEqxCJRsBknq","executionInfo":{"status":"ok","timestamp":1673990508611,"user_tz":360,"elapsed":146,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Import libraries\n","import numpy as np # Matrices and vectors\n","import pandas as pd # Data analysis and manipulation\n","import tensorflow as tf # Tensorflow\n","import tensorflow_datasets as tfds # Dataset\n","\n","from tensorflow.keras import layers # CNN layers\n","from google.colab import drive # Google drive\n"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KxHyg5HaB6dM"},"source":["# Data"]},{"cell_type":"code","metadata":{"id":"kDslamJ8CAlW"},"source":["# Mount Google drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BS9duEQF4dji"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"vDfKbThc4gkt","executionInfo":{"status":"ok","timestamp":1673990514277,"user_tz":360,"elapsed":161,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["class DCNN(tf.keras.Model):\n","    \n","    def __init__(self,\n","                 vocab_size,\n","                 emb_dim=128,\n","                 nb_filters=50,\n","                 FFN_units=512,\n","                 nb_classes=2,\n","                 dropout_rate=0.1,\n","                 training=False,\n","                 name=\"dcnn\"):\n","        super(DCNN, self).__init__(name=name)\n","        \n","        self.embedding = layers.Embedding(vocab_size,\n","                                          emb_dim)\n","        self.bigram = layers.Conv1D(filters=nb_filters, # Convolutions in one dimension\n","                                    kernel_size=2,\n","                                    padding=\"valid\",\n","                                    activation=\"relu\")\n","        self.trigram = layers.Conv1D(filters=nb_filters,\n","                                     kernel_size=3,\n","                                     padding=\"valid\",\n","                                     activation=\"relu\")\n","        self.fourgram = layers.Conv1D(filters=nb_filters, # An n-gram is a contiguous sequence of n items from a given sample of text or speech.\n","                                      kernel_size=4,\n","                                      padding=\"valid\",\n","                                      activation=\"relu\")\n","        self.pool = layers.GlobalMaxPool1D() \n","        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n","        self.dropout = layers.Dropout(rate=dropout_rate)\n","        if nb_classes == 2:\n","            self.last_dense = layers.Dense(units=1,\n","                                           activation=\"sigmoid\")\n","        else:\n","            self.last_dense = layers.Dense(units=nb_classes,\n","                                           activation=\"softmax\") # odds vector\n","    \n","    def call(self, inputs, training):\n","        x = self.embedding(inputs)\n","        x_1 = self.bigram(x)\n","        x_1 = self.pool(x_1)\n","        x_2 = self.trigram(x)\n","        x_2 = self.pool(x_2)\n","        x_3 = self.fourgram(x)\n","        x_3 = self.pool(x_3)\n","        \n","        merged = tf.concat([x_1, x_2, x_3], axis=-1) \n","        merged = self.dense_1(merged)\n","        merged = self.dropout(merged, training)\n","        output = self.last_dense(merged)\n","        \n","        return output"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"28D0OP6GjxMQ"},"source":["# Architecture and weights"]},{"cell_type":"code","metadata":{"id":"yOlQ1sUKkH4g","executionInfo":{"status":"ok","timestamp":1673990518015,"user_tz":360,"elapsed":136,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Initialize the parameters\n","VOCAB_SIZE = 65540 #tokenizer.vocab_size \n","\n","EMB_DIM = 200\n","NB_FILTERS = 100\n","FFN_UNITS = 256\n","NB_CLASSES = 2  #len(set(train_labels))\n"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"-bZ6t4gHkTyX","executionInfo":{"status":"ok","timestamp":1673990519049,"user_tz":360,"elapsed":141,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Establish the architecture of the ANN\n","Dcnn = DCNN(vocab_size= VOCAB_SIZE,\n","            emb_dim=EMB_DIM,\n","            nb_filters=NB_FILTERS,\n","            FFN_units=FFN_UNITS,\n","            nb_classes=NB_CLASSES,training=False)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-xjgQmAmO1o","executionInfo":{"status":"ok","timestamp":1673990520376,"user_tz":360,"elapsed":320,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Generate the ANN architecture\n","Dcnn.build(input_shape=(1, VOCAB_SIZE))"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLWGbtnTjwiP","executionInfo":{"status":"ok","timestamp":1673990521158,"user_tz":360,"elapsed":142,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Load weights\n","Dcnn.load_weights('/content/drive/MyDrive/Colab Notebooks/tweets_NLP/Tweets Test/weightsTweet.h5')"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"SeoF0o7DoLGv","executionInfo":{"status":"ok","timestamp":1673990522293,"user_tz":360,"elapsed":167,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Compile\n","# Determine if the problem is biclass or multiclass\n","if NB_CLASSES == 2:\n","    Dcnn.compile(loss=\"binary_crossentropy\", # For biclass\n","                 optimizer=\"adam\",\n","                 metrics=[\"accuracy\"])\n","else:\n","    Dcnn.compile(loss=\"sparse_categorical_crossentropy\", # For multiclass\n","                 optimizer=\"adam\",\n","                 metrics=[\"sparse_categorical_accuracy\"])"],"execution_count":50,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SM1cT8jy_Qao"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"sDXtddBvtkPC","executionInfo":{"status":"ok","timestamp":1673991046827,"user_tz":360,"elapsed":645,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Load the encoder\n","tokenizer = tfds.deprecated.text.SubwordTextEncoder.load_from_file('/content/drive/MyDrive/Colab Notebooks/tweets_NLP/Tweets Test/encodeFile')\n"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwHs50BrzlK9","outputId":"43326122-aa17-46d8-ccac-501b4d01d25f","executionInfo":{"status":"ok","timestamp":1673991081275,"user_tz":360,"elapsed":172,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Encode text\n","encoded = tokenizer.encode(\"I love being with you\")\n","print(encoded)"],"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["[3, 54, 192, 26, 55]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovWwVYry6oVQ","outputId":"f4f38b09-e68d-4394-c9d4-e87af87ba0e3","executionInfo":{"status":"ok","timestamp":1673991048547,"user_tz":360,"elapsed":4,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Test ANN\n","Dcnn(np.array([encoded]), training=False).numpy()"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.9462931]], dtype=float32)"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"tWxbkmWP4ho_","executionInfo":{"status":"ok","timestamp":1673991049991,"user_tz":360,"elapsed":3,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Function to get the prediction\n","def get_prediction(sentence):\n","  encoded = tokenizer.encode(sentence)\n","  sentiment = Dcnn(np.array([encoded]), training=False).numpy()\n","  if sentiment  < 0.5:\n","    print(\"Negative sentiment: {} \".format(sentiment))\n","  else:\n","    print(\"Positive sentiment: {} \".format(sentiment))"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmwF-9ZM6Mv_","outputId":"0197dbce-4a4f-49c2-ae0f-1570ee1ae3d0","executionInfo":{"status":"ok","timestamp":1673991051197,"user_tz":360,"elapsed":168,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# See the RNA prediction\n","get_prediction(\"I love being with you\")"],"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Positive sentiment: [[0.9462931]] \n"]}]}]}