{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hxjcOgg9BK4-"},"source":["# Natural Language Processing for sentiment classification (Deep Learning)\n","\n","Óscar Poblete Sáenz <br> Course: Introduction to Artificial Intelligence<br>\n","Teacher: Elizabeth Guevara Martinez<br>\n","Universidad Anáhuac <br> <br>\n","Sources:<br>\n","\n","Zhang, Ye & Wallace, Byron.  A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification. arXiv.  2015<br>\n","Vishnu K https://digitaltesseract.com/sentiment-analyzer-using-convolutional-neural-network/\n"]},{"cell_type":"code","metadata":{"id":"gEqxCJRsBknq","executionInfo":{"status":"ok","timestamp":1674090997933,"user_tz":360,"elapsed":5233,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Import libraries\n","import numpy as np # Matrices and vectors\n","import math # Math instructions\n","import re # Regex for string cleaning\n","import pandas as pd # Data analysis and manipulation\n","import tensorflow as tf # Tensorflow\n","import tensorflow_datasets as tfds # Dataset\n","\n","from tensorflow.keras import layers # CNN layers\n","from bs4 import BeautifulSoup # Pulling data out of HTML and XML files\n","from google.colab import drive # Google drive"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KxHyg5HaB6dM"},"source":["# Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDslamJ8CAlW","outputId":"dbd08cfc-c108-4bf2-dfb5-d69fb939efdd","executionInfo":{"status":"ok","timestamp":1674091037993,"user_tz":360,"elapsed":38051,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Mount Google drive\n","drive.mount(\"/content/drive\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"uX9vajTODHC1","executionInfo":{"status":"ok","timestamp":1674091056644,"user_tz":360,"elapsed":15402,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Create a list ‘cols’ that holds the column names of our dataset\n","cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n","\n","# Store train.csv file in a variable to use it later for other steps\n","data = pd.read_csv(\n","    \"/content/drive/MyDrive/Colab Notebooks/tweets_NLP/Tweets/trainTweets.csv\",\n","    header=None,\n","    names=cols,\n","    engine=\"python\",\n","    encoding=\"latin1\"\n",")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lri1yZEaGpgh"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"XyPmCSZyGsOv"},"source":["# # Remove columns that are not required\n","# data.drop([\"id\", \"date\", \"query\", \"user\"], axis=1, inplace=True)\n","# # If the columns have already been deleted and this instruction is run again, it will mark an error."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdAkF-5VHkvt","executionInfo":{"status":"ok","timestamp":1674091060268,"user_tz":360,"elapsed":337,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Message cleansing function\n","def clean_tweet(tweet):\n","    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n","   # Remove the @ and its mention\n","    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet) # r is line, + from @ to the end is taken as one\n","   # Remove URL links\n","    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet) # ? makes the previous element may or may not be\n","   # Keeping only letters\n","    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet) # ^ except\n","   # Remove extra whitespace\n","    tweet = re.sub(r\" +\", ' ', tweet) \n","    return tweet"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVSMvTvdKZW3"},"source":["# # Clean messages \n","# data_clean = [clean_tweet(tweet) for tweet in data.text]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FHAejLcUL5yB","executionInfo":{"status":"ok","timestamp":1674091063170,"user_tz":360,"elapsed":330,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# 4 is used instead of 1 to denote positive sentiments. So, all the occurrences of 4 have to be replaced by 1\n","set(data.sentiment)\n","data_labels = data.sentiment.values\n","data_labels[data_labels == 4] = 1"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdFuwiIBNEpE","outputId":"7f7dc84c-a750-459b-abcf-e6cb1057a949","executionInfo":{"status":"ok","timestamp":1674091066161,"user_tz":360,"elapsed":307,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Verify labels\n","set(data.sentiment)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0, 1}"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"rAEoM6soOOQ9"},"source":["# Conversion (vectors)\n"]},{"cell_type":"code","metadata":{"id":"n7Y5Ma8lOVu9"},"source":["# # Replace each word with a vector\n","# tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","#     data_clean, target_vocab_size=2**16\n","# )\n","\n","# data_inputs = [tokenizer.encode(sentence) for sentence in data_clean]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0R6CLXIynRJ"},"source":["# Save the encoder\n","# tokenizer.save_to_file('/content/drive/MyDrive/RNA/Tweets/encodeFile')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9qgxkdr3jtE"},"source":["# # Perform padding so all vectors are the same size\n","# # We take the largest word and from there the smallest words we make padding, we fill\n","# # cells with 0\n","# MAX_LEN = max([len(sentence) for sentence in data_inputs])\n","# data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\n","#                                                             value=0,\n","#                                                             padding=\"post\", #Everything after that is filled with zeros.\n","#                                                             maxlen=MAX_LEN)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wb8lC7b5ZrCp","executionInfo":{"status":"ok","timestamp":1674091114884,"user_tz":360,"elapsed":8189,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Load the saved inputs\n","data_inputs=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tweets_NLP/Tweets/data_inputs.csv').values"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"CAU_ug5U4OyU","executionInfo":{"status":"ok","timestamp":1674091159214,"user_tz":360,"elapsed":1785,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["from sklearn.model_selection import train_test_split\n","# Split into training and test sets\n","train_inputs, test_inputs, train_labels, test_labels = train_test_split(data_inputs, data_labels, test_size=0.6)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAFf4K8iaY4I"},"source":["# train_inputs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BS9duEQF4dji"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"vDfKbThc4gkt","executionInfo":{"status":"ok","timestamp":1674091163547,"user_tz":360,"elapsed":353,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["class DCNN(tf.keras.Model):\n","    \n","    def __init__(self,\n","                 vocab_size,\n","                 emb_dim=128,\n","                 nb_filters=50,\n","                 FFN_units=512,\n","                 nb_classes=2,\n","                 dropout_rate=0.1,\n","                 training=False,\n","                 name=\"dcnn\"):\n","        super(DCNN, self).__init__(name=name)\n","        \n","        self.embedding = layers.Embedding(vocab_size,\n","                                          emb_dim)\n","        self.bigram = layers.Conv1D(filters=nb_filters,\n","                                    kernel_size=2,\n","                                    padding=\"valid\",\n","                                    activation=\"relu\")\n","        self.trigram = layers.Conv1D(filters=nb_filters,\n","                                     kernel_size=3,\n","                                     padding=\"valid\",\n","                                     activation=\"relu\")\n","        self.fourgram = layers.Conv1D(filters=nb_filters,\n","                                      kernel_size=4,\n","                                      padding=\"valid\",\n","                                      activation=\"relu\")\n","        self.pool = layers.GlobalMaxPool1D() \n","        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n","        self.dropout = layers.Dropout(rate=dropout_rate)\n","        if nb_classes == 2:\n","            self.last_dense = layers.Dense(units=1,\n","                                           activation=\"sigmoid\")\n","        else:\n","            self.last_dense = layers.Dense(units=nb_classes,\n","                                           activation=\"softmax\")\n","    \n","    def call(self, inputs, training):\n","        x = self.embedding(inputs)\n","        x_1 = self.bigram(x)\n","        x_1 = self.pool(x_1)\n","        x_2 = self.trigram(x)\n","        x_2 = self.pool(x_2)\n","        x_3 = self.fourgram(x)\n","        x_3 = self.pool(x_3)\n","        \n","        merged = tf.concat([x_1, x_2, x_3], axis=-1) \n","        merged = self.dense_1(merged)\n","        merged = self.dropout(merged, training)\n","        output = self.last_dense(merged)\n","        \n","        return output"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmeiRG6i9HWZ","executionInfo":{"status":"ok","timestamp":1674091166452,"user_tz":360,"elapsed":2,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# # Define training parameters\n","\n","# VOCAB_SIZE = 65540 #tokenizer.vocab_size \n","\n","# EMB_DIM = 200\n","# NB_FILTERS = 100\n","# FFN_UNITS = 256\n","# NB_CLASSES = 2  #len(set(train_labels))\n","\n","# DROPOUT_RATE = 0.2\n","\n","BATCH_SIZE = 32\n","# NB_EPOCHS = 1"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"DLvAWT9O9Lct"},"source":["# Generate the model architecture\n","# Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n","#             emb_dim=EMB_DIM,\n","#             nb_filters=NB_FILTERS,\n","#             FFN_units=FFN_UNITS,\n","#             nb_classes=NB_CLASSES,\n","#             dropout_rate=DROPOUT_RATE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GkbP1XEz9NJM"},"source":["# # Determine if the problem is biclass or multiclass\n","# if NB_CLASSES == 2:\n","#     Dcnn.compile(loss=\"binary_crossentropy\", # For biclass\n","#                  optimizer=\"adam\",\n","#                  metrics=[\"accuracy\"])\n","# else:\n","#     Dcnn.compile(loss=\"sparse_categorical_crossentropy\", # For multiclass\n","#                  optimizer=\"adam\",\n","#                  metrics=[\"sparse_categorical_accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEcemfwh-VGu"},"source":["# # Save the training results\n","# checkpoint_path = \"/content/drive/MyDrive/Colab Notebooks/tweets_NLP/Tweets\"\n","\n","# ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n","\n","# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# if ckpt_manager.latest_checkpoint:\n","#     ckpt.restore(ckpt_manager.latest_checkpoint)\n","#     print(\"Last checkpoint restored!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"snsm04olTzDZ"},"source":["# Class to save checkpoints\n","# class saveCallback(tf.keras.callbacks.Callback):\n","#   def on_epoch_end(self, epoch, logs=None):\n","#     ckpt_manager.save()\n","#     print(\"Checkpoint en {}.\".format(checkpoint_path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LJUj-jaq-6XI"},"source":["# # Train the model\n","# Dcnn.fit(train_inputs,\n","#          train_labels,\n","#          batch_size=BATCH_SIZE,\n","#          epochs=NB_EPOCHS,\n","#          callbacks = [saveCallback()]\n","#          )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMq8k3fKeieI"},"source":["# Save weights at the end of the training\n","# Dcnn.save_weights('/content/drive/MyDrive/Colab Notebooks/tweets_NLP/Tweets Test/weightsTweet.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"28D0OP6GjxMQ"},"source":["# Architecture and weights"]},{"cell_type":"code","metadata":{"id":"yOlQ1sUKkH4g","executionInfo":{"status":"ok","timestamp":1674091171899,"user_tz":360,"elapsed":2,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Initialize the parameters\n","VOCAB_SIZE = 65540 #tokenizer.vocab_size \n","\n","EMB_DIM = 200\n","NB_FILTERS = 100\n","FFN_UNITS = 256\n","NB_CLASSES = 2  #len(set(train_labels))\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"-bZ6t4gHkTyX","executionInfo":{"status":"ok","timestamp":1674091176532,"user_tz":360,"elapsed":3091,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Establish the architecture of the ANN\n","Dcnn = DCNN(vocab_size= VOCAB_SIZE,\n","            emb_dim=EMB_DIM,\n","            nb_filters=NB_FILTERS,\n","            FFN_units=FFN_UNITS,\n","            nb_classes=NB_CLASSES,training=False)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-xjgQmAmO1o","executionInfo":{"status":"ok","timestamp":1674091180645,"user_tz":360,"elapsed":2,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Generate architecture\n","Dcnn.build(input_shape=(1, VOCAB_SIZE))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLWGbtnTjwiP","executionInfo":{"status":"ok","timestamp":1674091204881,"user_tz":360,"elapsed":347,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Load weights\n","Dcnn.load_weights('/content/drive/MyDrive/Colab Notebooks/tweets_NLP/Tweets Test/weightsTweet.h5')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"SeoF0o7DoLGv","executionInfo":{"status":"ok","timestamp":1674091246256,"user_tz":360,"elapsed":380,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Compile\n","# Determine if the problem is biclass or multiclass\n","if NB_CLASSES == 2:\n","    Dcnn.compile(loss=\"binary_crossentropy\", # If it is biclass then loss must be like this\n","                 optimizer=\"adam\",\n","                 metrics=[\"accuracy\"])\n","else:\n","    Dcnn.compile(loss=\"sparse_categorical_crossentropy\", # If it is multiclass then loss must be like this\n","                 optimizer=\"adam\",\n","                 metrics=[\"sparse_categorical_accuracy\"])"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SM1cT8jy_Qao"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"nkIW8I5Z_SuH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5200d10-8b98-4b5d-9f13-326abc6e2ace","executionInfo":{"status":"ok","timestamp":1674091393849,"user_tz":360,"elapsed":144344,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["results = Dcnn.evaluate(test_inputs, test_labels, batch_size=BATCH_SIZE)\n","print(results)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["30000/30000 [==============================] - 91s 3ms/step - loss: 0.2387 - accuracy: 0.9094\n","[0.2387446165084839, 0.9094114303588867]\n"]}]},{"cell_type":"code","metadata":{"id":"sDXtddBvtkPC","executionInfo":{"status":"ok","timestamp":1674091453595,"user_tz":360,"elapsed":1215,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Load the encoder\n","tokenizer = tfds.deprecated.text.SubwordTextEncoder.load_from_file('/content/drive/MyDrive/Colab Notebooks/tweets_NLP/Tweets Test/encodeFile')"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwHs50BrzlK9","outputId":"790c8619-71b9-410d-d65d-c10c857384d5","executionInfo":{"status":"ok","timestamp":1674091470394,"user_tz":360,"elapsed":409,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Encode text\n","encoded = tokenizer.encode(\"I hate being with you\")\n","print(encoded)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[3, 161, 192, 26, 55]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovWwVYry6oVQ","outputId":"1120b5e1-b592-4be9-afe9-304b1c9c9060","executionInfo":{"status":"ok","timestamp":1674091472246,"user_tz":360,"elapsed":6,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Test ANN\n","Dcnn(np.array([encoded]), training=False).numpy()"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.00765597]], dtype=float32)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"tWxbkmWP4ho_","executionInfo":{"status":"ok","timestamp":1674091474584,"user_tz":360,"elapsed":336,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# Function to get the prediction\n","def get_prediction(sentence):\n","  encoded = tokenizer.encode(sentence)\n","  sentiment = Dcnn(np.array([encoded]), training=False).numpy()\n","  if sentiment  < 0.5:\n","    print(\"Negative sentiment: {} \".format(sentiment))\n","  else:\n","    print(\"Positive sentiment: {} \".format(sentiment))"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmwF-9ZM6Mv_","outputId":"940bc7e6-3879-400e-f4cc-5d05d92be129","executionInfo":{"status":"ok","timestamp":1674091475740,"user_tz":360,"elapsed":3,"user":{"displayName":"Oscar Estudios","userId":"07819016775927763439"}}},"source":["# See the RNA prediction\n","get_prediction(\"I hate being with you\")"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Negative sentiment: [[0.00765597]] \n"]}]}]}