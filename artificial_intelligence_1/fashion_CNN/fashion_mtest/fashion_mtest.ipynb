{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXB59gnJJMc-"
      },
      "source": [
        "#Clothes classification with CNN (Deep Learning)\n",
        "Óscar Poblete Sáenz <br>\n",
        "Course: Introduction to Artificial Intelligence <br>\n",
        "Teacher: Elizabeth Guevara Martinez<br>\n",
        "Universidad Anáhuac <br>\n",
        "\n",
        "The goal is to develop a model to detect and classify types of garments from images.\n",
        "There are 48,000 training images and 10,000 test images that belong to **10 classes or labels**:\n",
        "\n",
        "#Classes <br>\n",
        "\n",
        "0 T-shirt/top<br>\n",
        "1 Trouser<br>\n",
        "2 Pullover<br>\n",
        "3 Dress<br>\n",
        "4 Coat<br>\n",
        "5 Sandal<br>\n",
        "6 Shirt<br>\n",
        "7 Sneaker<br>\n",
        "8 Bag<br>\n",
        "9 Ankle boot<br>\n",
        "\n",
        "#Sources: \n",
        "\n",
        "The original dataset was downloaded from https://github.com/zalandoresearch/fashion-mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fhKgSFNdJSuo"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import tensorflow.keras # Tensorflow\n",
        "import numpy as np # Linear algebra\n",
        "import pandas as pd # Data manipulation and analysis\n",
        "import matplotlib.pyplot as plt # Graph\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAMZR_ADJjHw",
        "outputId": "61bc0295-92ae-471c-af3c-e4b1845f669f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test data\n",
        "test_df=pd.read_csv('fashion-mnist_test.csv')\n",
        "\n",
        "# Convert to floats\n",
        "test_data=np.array(test_df,dtype='float32')\n",
        "\n",
        "# Data size\n",
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T6B61l_rJ9VY"
      },
      "outputs": [],
      "source": [
        "# Split values from the test set\n",
        "x_test=test_data[:,1:]/255 # It's already an array, no need to use iloc. Save all values except labels\n",
        "# Divide by 255 to normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "OzNNccbNIlK3",
        "outputId": "6a17fb8f-adda-4ba7-8305-4cc4d3449b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image of the garment\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f372f6adf70>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Adjust vector dimensions. from 784 to 28\n",
        "image=x_test[random.randint(0,1000),:].reshape((28,28)) # Select random image\n",
        "\n",
        "# Show image\n",
        "print(\"Image of the garment\")\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f6nVK9grL5Vj"
      },
      "outputs": [],
      "source": [
        "# Load model obtained in fashion_CNN.ipynb\n",
        "model = tensorflow.keras.models.load_model('/content/modelFashion.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D0wAnaSL-CG",
        "outputId": "012090e1-8049-4d0c-d3a8-ce419f01916e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                173088    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173,738\n",
            "Trainable params: 173,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# CNN architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keKEcL6ceVQF",
        "outputId": "19409be6-cec1-459e-b71c-2a69dcc014f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 28, 28, 1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Input layer\n",
        "model.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0wbXLPNyLFvb"
      },
      "outputs": [],
      "source": [
        "# Generate an array to save images and test the model\n",
        "data = np.ndarray(shape=(1, 28, 28), dtype=np.float32)\n",
        "# Load the image in an array\n",
        "data[0] = image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLSxMNr_L2Wg",
        "outputId": "dbce7eed-a317-4ec6-f255-5d99c0b7f424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 346ms/step\n",
            "[1.8436001e-05 1.1498943e-06 6.2535313e-05 1.5913089e-05 2.1115262e-05\n",
            " 9.9858367e-01 8.9185796e-06 6.9060181e-05 1.2191399e-03 8.3952656e-08]\n"
          ]
        }
      ],
      "source": [
        "# Make prediction\n",
        "prediction=model.predict(data)[0]\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dD0S0J4LMBq6"
      },
      "outputs": [],
      "source": [
        "# Load labels\n",
        "# Separating with line break to make a list of values\n",
        "with open('labels.txt', 'r') as f:\n",
        "  labels = f.read().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL3MrNnsMEYg",
        "outputId": "891e12d9-145c-48b7-9d46-aac51f674d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most likely class is '5 Sandal' with a confidence of 99.858%\n"
          ]
        }
      ],
      "source": [
        "# Print model prediction\n",
        "index = np.argmax(prediction) # Take the maximum of the probabilities to obtain the class\n",
        "# It will tell us the most probable class for the image we loaded\n",
        "print(\"The most likely class is '{}' with a confidence of {}%\".format(labels[index], np.round(prediction[index]*100, 3)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
